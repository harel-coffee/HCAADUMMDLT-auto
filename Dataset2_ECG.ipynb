{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset2_ECG.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMp/P9EVGPDHk786OWQ6/3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidhunk/HCAADUMMDLT/blob/main/Dataset2_ECG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsvkmNGd_TYH",
        "outputId": "142c5f9e-224e-4389-c9e0-7950cf603c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "4.0 14.0\n",
            "54.0 11.0\n",
            "59.0 11.0\n",
            "66.0 10.0\n",
            "91.0 10.0\n",
            "106.0 11.0\n",
            "108.0 11.0\n",
            "116.0 11.0\n",
            "133.0 11.0\n",
            "174.0 11.0\n",
            "177.0 11.0\n",
            "193.0 11.0\n",
            "200.0 10.0\n",
            "204.0 11.0\n",
            "212.0 10.0\n",
            "217.0 11.0\n",
            "219.0 11.0\n",
            "238.0 10.0\n",
            "241.0 12.0\n",
            "243.0 11.0\n",
            "253.0 11.0\n",
            "279.0 11.0\n",
            "284.0 11.0\n",
            "298.0 11.0\n",
            "300.0 11.0\n",
            "308.0 11.0\n",
            "310.0 11.0\n",
            "350.0 11.0\n",
            "360.0 10.0\n",
            "372.0 10.0\n",
            "412.0 10.0\n",
            "420.0 11.0\n",
            "[ 8  6 10  1  7 14  1  1  1 10  3  1 10  6  1  1 10  1  1  1  1  1  1  1\n",
            "  1 16 14 10  2  2  6  1  1  1  4  1  1 10  1  6  1  1  1  1  1  4  5  1\n",
            "  6  1  1  1 10 16 16  6  1  1  6  1  5  5  1  1  1  1  2  1  6  1  6 16\n",
            "  1  1  1 10  3  2  1  1  1  1  2  4  6  9  2  4  9  9  1  4  1  5 10  1\n",
            " 10  1  1  1  4  1  1  1  6  4  6  1  2  1  1  1  1  1  6  1 16  1  1  1\n",
            "  1  1  1  1  1  1  1 10  1  1  1  1  1  1 10  1  1 10  1  1  1  5  1  1\n",
            " 10 10 10  1  1 10  1  1  1  6 16  1  1  2  1  1  1  1  1  1  1  1  1  1\n",
            "  5  4  1  1  1 10 15  6  1  1  1  2  1 16  1  4  2  4  2  2 14  9  1  1\n",
            "  2  2  1  1  1 16 16  1  2  1  1  1  3  1  1  9  1 10 10  1  2  2  4  1\n",
            "  2 15  3 16  1  1  6  1 10  3  1 16  1  1  1  4  1  1  1  2  1  2  1  1\n",
            "  1  1  1 15  1  2  1  1  4  1 10  4  3  3  1  1  2  3  5  2  1 16  1  1\n",
            "  1  1 10  1  1  1  1  1  6  1  1  2  1  2 10  1  1  1  1  6 10  3  1  1\n",
            "  1  1  1 10  1 10  2  2  2 10 10  1 15  1  6  3  2  1 16  6  2  7  1  1\n",
            " 10 10  1  1  5  1  1 10  5  1  2  2 10  1 10  7  1  2  1  1 16  1 10  1\n",
            " 10  1  1  1 16 10  1  6 10  1 10  1  5  1  1  2  1 10 16  1  3  2  6  2\n",
            "  2  3 16 10  6  1  2  2  2  1  9  1  2  1  5  2  8  1  1 10 16  3  1  1\n",
            "  6  1 16  5  9  1  1  1  1  1  1  9  1 10  3  1 10 14  1  5  1  1  1  1\n",
            "  1 16  4  2 16  1  1  1  1 10  1  1 15  1  1  1  9  1  1 10  1 16 10  6\n",
            " 10  3  1  1  1  1  1  1  1  1  1 10  1  1  1  1 10  2  1  1]\n",
            "4.0 14.0\n",
            "54.0 11.0\n",
            "59.0 11.0\n",
            "66.0 10.0\n",
            "91.0 10.0\n",
            "106.0 11.0\n",
            "108.0 11.0\n",
            "116.0 11.0\n",
            "133.0 11.0\n",
            "174.0 11.0\n",
            "177.0 11.0\n",
            "193.0 11.0\n",
            "200.0 10.0\n",
            "204.0 11.0\n",
            "212.0 10.0\n",
            "217.0 11.0\n",
            "219.0 11.0\n",
            "238.0 10.0\n",
            "241.0 12.0\n",
            "243.0 11.0\n",
            "253.0 11.0\n",
            "279.0 11.0\n",
            "284.0 11.0\n",
            "298.0 11.0\n",
            "300.0 11.0\n",
            "308.0 11.0\n",
            "310.0 11.0\n",
            "350.0 11.0\n",
            "360.0 10.0\n",
            "372.0 10.0\n",
            "412.0 10.0\n",
            "420.0 11.0\n",
            "mean=74.29867256637168\n",
            "[74.31974563]\n",
            "74.0\n",
            "mean=35.51106194690266\n",
            "[33.85893352]\n",
            "33.0\n",
            "[38.19704998]\n",
            "38.0\n",
            "[38.71872755]\n",
            "38.0\n",
            "[34.82623592]\n",
            "34.0\n",
            "[38.25907918]\n",
            "38.0\n",
            "[37.56207603]\n",
            "37.0\n",
            "[33.89352222]\n",
            "33.0\n",
            "[36.10872397]\n",
            "36.0\n",
            "mean=46.533185840707965\n",
            "[46.1121209]\n",
            "46.0\n",
            "[46.09766996]\n",
            "46.0\n",
            "[46.65211102]\n",
            "46.0\n",
            "[46.51641163]\n",
            "46.0\n",
            "[46.56163271]\n",
            "46.0\n",
            "[46.84921198]\n",
            "46.0\n",
            "[46.95016671]\n",
            "46.0\n",
            "[46.19046668]\n",
            "46.0\n",
            "[46.76176656]\n",
            "46.0\n",
            "[46.76225686]\n",
            "46.0\n",
            "[46.27037235]\n",
            "46.0\n",
            "[46.32980536]\n",
            "46.0\n",
            "[46.53944666]\n",
            "46.0\n",
            "[46.52232747]\n",
            "46.0\n",
            "[46.78194811]\n",
            "46.0\n",
            "[46.87308387]\n",
            "46.0\n",
            "[46.59775665]\n",
            "46.0\n",
            "[46.56671657]\n",
            "46.0\n",
            "[46.06813726]\n",
            "46.0\n",
            "[46.56280742]\n",
            "46.0\n",
            "[46.76227204]\n",
            "46.0\n",
            "[46.87118566]\n",
            "46.0\n",
            "mean=36.63495575221239\n",
            "[36.82892399]\n",
            "36.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "import pywt\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, AvgPool1D, Flatten, Dense, Dropout, Softmax\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.layers import LeakyReLU\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Activation, Add, Embedding, Conv1DTranspose, RepeatVector, Softmax, Conv1D, \\\n",
        "    Flatten, UpSampling1D, MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.python.keras.layers.recurrent import LSTM\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "from keras.models import model_from_json\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "import glob\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "def mean_column( X, col_num ):\n",
        "\tmean=0.0\n",
        "\tc=0\n",
        "\tfor i in range(0,452):\n",
        "\t\tif(X[i][col_num] !=\"?\"):\t\n",
        "\t\t\tmean=mean+X[i][col_num].astype(float)\n",
        "\t\t\tc=c+1\n",
        "\tmean=mean/c\n",
        "\treturn mean\n",
        "\n",
        "def standard_deviation_column( X, col_num ,mean):\n",
        "\tsd=0.0\n",
        "\tc=0\n",
        "\tfor i in range(0,452):\n",
        "\t\tif(X[i][col_num] !=\"?\"):\t\n",
        "\t\t\tsd=(X[i][col_num].astype(float)-mean)**2\n",
        "\t\t\tc=c+1\n",
        "\tsd=sd/(c-1)\n",
        "\tsd=sd**0.5\n",
        "\treturn sd\n",
        "\t\n",
        "\t\n",
        "def convert_strarr_floatarr( arr, X):\n",
        "\tfor i in range(0,452):\n",
        "\t\tfor j in range(0,278):\n",
        "\t\t\tif(arr[i][j]==\"?\"):\t\n",
        "\t\t\t\tX[i][j]=0.0\n",
        "\t\t\telse:\n",
        "\t\t\t\tX[i][j]=arr[i][j].astype(float)\n",
        "\treturn\n",
        "\t\t\t\t\t\n",
        "\t\t\t\n",
        "reader=csv.reader(open(\"/content/drive/MyDrive/arrhythmia.csv\",\"r\"),delimiter=\",\")\n",
        "arr=list(reader)\n",
        "arr=np.array(arr)\n",
        "data=np.zeros((452,2))\n",
        "c=0\n",
        "for i in range(0,452):\n",
        "\tfor j in range(0,279):\n",
        "\t\tif(arr[i][j] ==\"?\"):\t\n",
        "\t\t\tdata[c][0]=i\n",
        "\t\t\tdata[c][1]=j\n",
        "\t\t\tc=c+1\n",
        "\n",
        "#majority of the values are missing so delete coulmn 13\n",
        "#find the columns with missing values\t\t\t\n",
        "for i in range(0,c):\n",
        "\tif(data[i][1]!=13):\n",
        "\t\tprint(data[i][0],data[i][1])\n",
        "\n",
        "#remove coulmn 13\n",
        "arr = np.delete(arr,13,1)\n",
        "\n",
        "#create feature matrix\n",
        "X=np.zeros((452,278),dtype=float)\n",
        "convert_strarr_floatarr(arr,X)\n",
        "\n",
        "#create result vector\n",
        "y=np.zeros((452),dtype=int)\n",
        "for i in range(0,452):\n",
        "\ty[i]=arr[i][278].astype(int)\n",
        "print (y)\n",
        "\n",
        "#find the columns with missing values\t\t\t\n",
        "for i in range(0,c):\n",
        "\tif(data[i][1]!=13):\n",
        "\t\tprint(data[i][0],data[i][1])\n",
        "\t\t\t\n",
        "#calculate mean for column 13(initially 14),11,10,12\n",
        "mean=mean_column(X,13)\n",
        "print (\"mean=\"+str(mean))\n",
        "sd=standard_deviation_column(X,13,mean)\n",
        "\n",
        "for i in range(0,452):\n",
        "\tif(arr[i][13]==\"?\"):\n",
        "\t\tval = np.random.normal(mean,sd,1)\n",
        "\t\tprint (val)\n",
        "\t\tX[i][13]=(val).astype(int)\n",
        "\t\tprint (X[i][13])\n",
        "\t\t\n",
        "mean=mean_column(X,10)\n",
        "print (\"mean=\"+str(mean))\n",
        "sd=standard_deviation_column(X,10,mean)\n",
        "\n",
        "for i in range(0,452):\n",
        "\tif(arr[i][10]==\"?\"):\n",
        "\t\tval = np.random.normal(mean,sd,1)\n",
        "\t\tprint(val)\n",
        "\t\tX[i][10]=(val).astype(int)\n",
        "\t\tprint (X[i][10])\n",
        "\n",
        "mean=mean_column(X,11)\n",
        "print (\"mean=\"+str(mean))\n",
        "sd=standard_deviation_column(X,11,mean)\n",
        "\n",
        "for i in range(0,452):\n",
        "\tif(arr[i][11]==\"?\"):\n",
        "\t\tval = np.random.normal(mean,sd,1)\n",
        "\t\tprint (val)\n",
        "\t\tX[i][11]=(val).astype(int)\n",
        "\t\tprint (X[i][11])\n",
        "\n",
        "mean=mean_column(X,12)\n",
        "print (\"mean=\"+str(mean))\n",
        "sd=standard_deviation_column(X,12,mean)\n",
        "\n",
        "for i in range(0,452):\n",
        "\tif(arr[i][12]==\"?\"):\n",
        "\t\tval = np.random.normal(mean,sd,1)\n",
        "\t\tprint (val)\n",
        "\t\tX[i][12]=(val).astype(int)\n",
        "\t\tprint (X[i][12])\n",
        "#reduce number of classes\n",
        "for i in range(0,452):\n",
        "\tif (y[i]>=14):\n",
        "\t\ty[i]=y[i]-3\n",
        "\n",
        "np.savetxt(\"feature.csv\", X, fmt='%s', delimiter=\",\")\n",
        "np.savetxt(\"target_output.csv\", y, fmt='%s', delimiter=\",\")\n",
        "#result=numpy.array(x).astype(\"str\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "import pandas\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "def convert_strarr_floatarr( arr, X):\n",
        "\tfor i in range(0,452):\n",
        "\t\tfor j in range(0,278):\n",
        "\t\t\t\tX[i][j]=arr[i][j].astype(float)\n",
        "\treturn\n",
        "\n",
        "#Feature extraction\n",
        "\n",
        "\n",
        "#create feature matrix\n",
        "reader=csv.reader(open(\"feature.csv\",\"r\"),delimiter=\",\")\n",
        "X=list(reader)\n",
        "X=np.array(X)\n",
        "X=X.astype(float)\n",
        "\n",
        "#create result vector\n",
        "reader=csv.reader(open(\"target_output.csv\",\"r\"),delimiter=\",\")\n",
        "Y=list(reader)\n",
        "Y=np.array(Y)\n",
        "Y=Y.astype(int)\n",
        "\n",
        "\t\n",
        "\n",
        "#applying PCA to get pricipal attributes\n",
        "pca = PCA(n_components=50)\n",
        "X=pca.fit_transform(X)\n",
        "\n",
        "print (pca.explained_variance_ratio_)\n",
        "\n",
        "np.savetxt(\"reduced_features.csv\",X, fmt='%s', delimiter=\",\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBDZ2XZgBg90",
        "outputId": "3cdcdca1-95c8-416e-acdf-9af7f4dc3dd2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.16006843 0.10649796 0.09127897 0.08931583 0.05613585 0.04921591\n",
            " 0.04423136 0.03617308 0.03154679 0.03025858 0.02399531 0.02245054\n",
            " 0.02171073 0.01852524 0.01652503 0.01450779 0.01334739 0.01266406\n",
            " 0.0097724  0.0092824  0.00820602 0.00772072 0.00721751 0.00675677\n",
            " 0.00635547 0.00588719 0.00563404 0.00533039 0.00514361 0.004805\n",
            " 0.00448627 0.00431938 0.00403253 0.00377634 0.00351694 0.00325755\n",
            " 0.00320184 0.00303185 0.00276049 0.00263769 0.0023929  0.00235461\n",
            " 0.00230287 0.00224244 0.00209527 0.00207428 0.00182272 0.00169329\n",
            " 0.00155249 0.00144808]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "readerF=csv.reader(open(\"reduced_features.csv\",\"r\"),delimiter=\",\")\n",
        "X=list(readerF)\n",
        "X=np.array(X)\n",
        "X=X.astype(float)\n",
        "\n",
        "#feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X=sc.fit_transform(X)\n",
        "\n",
        "readerL=csv.reader(open(\"target_output.csv\",\"r\"),delimiter=\",\")\n",
        "Y=list(readerL)\n",
        "Y=np.array(Y)\n",
        "Y=Y.astype(int)\n",
        "\n",
        "#splitting the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test= train_test_split(X,Y,test_size=0.40, random_state=0)\n",
        "\n",
        "\n",
        "Y_train=np.transpose(Y_train)\n",
        "Y_test=np.transpose(Y_test)\n",
        "\n",
        "#one hot encoding for multiclass (Training labels)\n",
        "one_hot_encoded=list()\n",
        "for value in range (0,Y_train.shape[1]):\n",
        "\tout=list()\n",
        "\tout=[0 for i in range(13)]\n",
        "\tout[Y_train[0][value]-1]=1\n",
        "\tone_hot_encoded.append(out)\n",
        " \n",
        "\n",
        "Y_train=one_hot_encoded\n",
        "Y_train=np.array(Y_train)\n",
        "\n",
        "\n",
        "\n",
        "#one hot encoding for multiclass (Testing labels)\n",
        "one_hot_encoded2=list()\n",
        "for value in range (0,Y_test.shape[1]):\n",
        "\tout2=list()\n",
        "\tout2=[0 for i in range(13)]\n",
        "\tout2[Y_test[0][value]-1]=1\n",
        "\tone_hot_encoded2.append(out2)\n",
        " \n",
        "Y_test=one_hot_encoded2\n",
        "Y_test=np.array(Y_test)\n",
        "\n",
        "print(\"shape of XTrain =\"+str(X_train.shape))\n",
        "print(\"shape of YTrain =\"+str(Y_train.shape))\n",
        "\n",
        "print(\"shape of XTest =\"+str(X_test.shape))\n",
        "print(\"shape of YTest =\"+str(Y_test.shape))\n",
        "\n",
        "# X_train=np.transpose(X_train)\n",
        "# Y_train=np.transpose(Y_train)\n",
        "\n",
        "# X_test=np.transpose(X_test)\n",
        "# Y_test=np.transpose(Y_test)\n",
        "\n",
        "\n",
        "# print(\"T shape of XTrain =\"+str(X_train.shape))\n",
        "# print(\"T shape of YTrain =\"+str(Y_train.shape))\n",
        "\n",
        "# print(\"T shape of XTest =\"+str(X_test.shape))\n",
        "# print(\"T shape of YTest =\"+str(Y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkHQ6KxMB6Mi",
        "outputId": "a0aea4c2-05be-446b-9309-e938aa28112c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of XTrain =(271, 50)\n",
            "shape of YTrain =(271, 13)\n",
            "shape of XTest =(181, 50)\n",
            "shape of YTest =(181, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Y_test = np.argmax(Y_test, axis=1)\n",
        "# Y_test = pd.DataFrame(Y_test)\n",
        "# per_class = Y_test[Y_test.shape[1]-1].value_counts()\n",
        "# print(per_class)\n",
        "# plt.figure(figsize=(20,10))\n",
        "# my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
        "# # plt.pie(per_class, labels=['1','2','3','4','5','6','7','8','9','10','11','12','13'], colors=['tab:blue','tab:orange','tab:purple','tab:olive','tab:green'],autopct='%1.1f%%')\n",
        "# p=plt.gcf()\n",
        "# p.gca().add_artist(my_circle)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "UfEFNVKMDEFm"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############LSTM\n",
        "\n",
        "# ac = tf.keras.layers.LeakyReLU(alpha=0.9)\n",
        "model1 = tf.keras.Sequential()\n",
        "model1.add(tf.keras.layers.LSTM(units = 64, activation='relu', input_shape = (50,1)))\n",
        "# model1.add(tf.keras.layers.Dropout(.5, noise_shape=None, seed=None))\n",
        "model1.add(Dense(13, activation='relu'))\n",
        "model1.add(tf.keras.layers.BatchNormalization())\n",
        "model1.add(Dense(13, activation='softmax'))\n",
        "model1.summary()\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model1.compile(optimizer=opt,\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# history = model1.fit(train_x, train_y, epochs = 250, validation_split = 0.40, batch_size = 25, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3s7G6LyHHM7",
        "outputId": "d6739853-cb2b-41fe-ac02-73958c4c341f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 64)                16896     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 13)                845       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 13)               52        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 13)                182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,975\n",
            "Trainable params: 17,949\n",
            "Non-trainable params: 26\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########CNN\n",
        "\n",
        "\n",
        "model3 = tf.keras.Sequential()\n",
        "model3.add(tf.keras.Input(shape = (50,1)))\n",
        "\n",
        "model3.add(Conv1D(2, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=1, strides=1))\n",
        "\n",
        "model3.add(Conv1D(2, kernel_size=4, strides=1, padding='same', activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=1, strides=1))\n",
        "\n",
        "model3.add(Conv1D(2, kernel_size=8, strides=1, padding='same', activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=1, strides=1))\n",
        "\n",
        "model3.add(tf.keras.layers.Dropout(.3, noise_shape=None, seed=None))\n",
        "model3.add(tf.keras.layers.Flatten(data_format=None))\n",
        "model3.add(tf.keras.layers.BatchNormalization())\n",
        "model3.add(Dense(13, activation='relu'))\n",
        "model3.add(Dense(13, activation='softmax'))\n",
        "model3.summary()\n",
        "\n",
        "model3.compile(optimizer=opt,\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# history2 = model3.fit(train_x, train_y, epochs = 250, validation_split = 0.40, batch_size = 25, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEoMRNLCHN-X",
        "outputId": "e2fb3c7b-ba3c-408a-d465-ea33e1d5191f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_18 (Conv1D)          (None, 50, 2)             6         \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 50, 2)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 50, 2)             18        \n",
            "                                                                 \n",
            " max_pooling1d_19 (MaxPoolin  (None, 50, 2)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_20 (Conv1D)          (None, 50, 2)             34        \n",
            "                                                                 \n",
            " max_pooling1d_20 (MaxPoolin  (None, 50, 2)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50, 2)             0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 100)               0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 100)              400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 13)                1313      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 13)                182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,953\n",
            "Trainable params: 1,753\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############ Merging all models\n",
        "\n",
        "mergedOut = Add()([model1.output, model3.output])\n",
        "newModel = Model([model1.input, model3.input], mergedOut)\n",
        "newModel.summary()\n",
        "\n",
        "newModel.compile(optimizer=opt,\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "newModel.fit([X_train, X_train], Y_train, epochs=500, batch_size=20, shuffle=False)\n",
        "\n",
        "preddd = newModel.predict([X_test, X_test])\n",
        "print(preddd.shape)\n",
        "preddd = np.argmax(preddd, axis=1)\n",
        "print(preddd)\n",
        "\n",
        "\n",
        "# #   Final Accuracy\n",
        "\n",
        "\n",
        "max_testNM = np.argmax(Y_test, axis=1)\n",
        "print(max_testNM)\n",
        "\n",
        "Accuracy = accuracy_score(max_testNM, preddd)\n",
        "NAccuracy = Accuracy * 100\n",
        "print('Merged Model Accuracy:', NAccuracy, '%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ82VdygHTDJ",
        "outputId": "25b63eed-e47f-4a70-f935-99b8d5dc16f3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 50, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 50, 2)        6           ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling1d_18 (MaxPooling1D  (None, 50, 2)       0           ['conv1d_18[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 50, 2)        18          ['max_pooling1d_18[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling1d_19 (MaxPooling1D  (None, 50, 2)       0           ['conv1d_19[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 50, 2)        34          ['max_pooling1d_19[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling1d_20 (MaxPooling1D  (None, 50, 2)       0           ['conv1d_20[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lstm_6_input (InputLayer)      [(None, 50, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 50, 2)        0           ['max_pooling1d_20[0][0]']       \n",
            "                                                                                                  \n",
            " lstm_6 (LSTM)                  (None, 64)           16896       ['lstm_6_input[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 100)          0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 13)           845         ['lstm_6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 100)         400         ['flatten_6[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 13)          52          ['dense_24[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 13)           1313        ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 13)           182         ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " dense_27 (Dense)               (None, 13)           182         ['dense_26[0][0]']               \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 13)           0           ['dense_25[0][0]',               \n",
            "                                                                  'dense_27[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,928\n",
            "Trainable params: 19,702\n",
            "Non-trainable params: 226\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/500\n",
            "14/14 [==============================] - 3s 94ms/step - loss: 2.5717 - accuracy: 0.1476\n",
            "Epoch 2/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 2.2740 - accuracy: 0.4354\n",
            "Epoch 3/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 2.0618 - accuracy: 0.5092\n",
            "Epoch 4/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 1.8819 - accuracy: 0.5424\n",
            "Epoch 5/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 1.7071 - accuracy: 0.5683\n",
            "Epoch 6/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 1.5777 - accuracy: 0.5646\n",
            "Epoch 7/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 1.5175 - accuracy: 0.5720\n",
            "Epoch 8/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 1.4733 - accuracy: 0.5793\n",
            "Epoch 9/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 1.4210 - accuracy: 0.5830\n",
            "Epoch 10/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 1.3315 - accuracy: 0.6089\n",
            "Epoch 11/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 1.2763 - accuracy: 0.6236\n",
            "Epoch 12/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 1.2404 - accuracy: 0.6310\n",
            "Epoch 13/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 1.2292 - accuracy: 0.6421\n",
            "Epoch 14/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 1.1710 - accuracy: 0.6421\n",
            "Epoch 15/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 1.1489 - accuracy: 0.6605\n",
            "Epoch 16/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 1.0945 - accuracy: 0.6568\n",
            "Epoch 17/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 1.0344 - accuracy: 0.6827\n",
            "Epoch 18/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 1.0142 - accuracy: 0.6827\n",
            "Epoch 19/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 1.0506 - accuracy: 0.6679\n",
            "Epoch 20/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 1.0282 - accuracy: 0.6827\n",
            "Epoch 21/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.9979 - accuracy: 0.6900\n",
            "Epoch 22/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.9011 - accuracy: 0.7122\n",
            "Epoch 23/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.8916 - accuracy: 0.7122\n",
            "Epoch 24/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.8794 - accuracy: 0.7122\n",
            "Epoch 25/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.8466 - accuracy: 0.7159\n",
            "Epoch 26/500\n",
            "14/14 [==============================] - 2s 149ms/step - loss: 0.8559 - accuracy: 0.7196\n",
            "Epoch 27/500\n",
            "14/14 [==============================] - 2s 151ms/step - loss: 0.7790 - accuracy: 0.7417\n",
            "Epoch 28/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.9036 - accuracy: 0.7159\n",
            "Epoch 29/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.8854 - accuracy: 0.7380\n",
            "Epoch 30/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.8445 - accuracy: 0.7269\n",
            "Epoch 31/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.7985 - accuracy: 0.7601\n",
            "Epoch 32/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.7905 - accuracy: 0.7380\n",
            "Epoch 33/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.7315 - accuracy: 0.7675\n",
            "Epoch 34/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.7107 - accuracy: 0.7712\n",
            "Epoch 35/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.6875 - accuracy: 0.7675\n",
            "Epoch 36/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.7178 - accuracy: 0.7491\n",
            "Epoch 37/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.6737 - accuracy: 0.7528\n",
            "Epoch 38/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.6771 - accuracy: 0.7232\n",
            "Epoch 39/500\n",
            "14/14 [==============================] - 2s 152ms/step - loss: 0.6756 - accuracy: 0.7380\n",
            "Epoch 40/500\n",
            "14/14 [==============================] - 3s 201ms/step - loss: 0.6421 - accuracy: 0.7749\n",
            "Epoch 41/500\n",
            "14/14 [==============================] - 1s 96ms/step - loss: 0.6336 - accuracy: 0.7565\n",
            "Epoch 42/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.6362 - accuracy: 0.7823\n",
            "Epoch 43/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.6248 - accuracy: 0.7601\n",
            "Epoch 44/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.5962 - accuracy: 0.7638\n",
            "Epoch 45/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.6075 - accuracy: 0.7675\n",
            "Epoch 46/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.5591 - accuracy: 0.7601\n",
            "Epoch 47/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.6100 - accuracy: 0.7306\n",
            "Epoch 48/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.6109 - accuracy: 0.7860\n",
            "Epoch 49/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.6590 - accuracy: 0.7565\n",
            "Epoch 50/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.6082 - accuracy: 0.7380\n",
            "Epoch 51/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.5584 - accuracy: 0.7897\n",
            "Epoch 52/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.5178 - accuracy: 0.7860\n",
            "Epoch 53/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.5255 - accuracy: 0.7897\n",
            "Epoch 54/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.5397 - accuracy: 0.7749\n",
            "Epoch 55/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.5684 - accuracy: 0.7749\n",
            "Epoch 56/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.5628 - accuracy: 0.7897\n",
            "Epoch 57/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.5810 - accuracy: 0.7712\n",
            "Epoch 58/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.5643 - accuracy: 0.7823\n",
            "Epoch 59/500\n",
            "14/14 [==============================] - 2s 127ms/step - loss: 0.5051 - accuracy: 0.8192\n",
            "Epoch 60/500\n",
            "14/14 [==============================] - 2s 164ms/step - loss: 0.5509 - accuracy: 0.7823\n",
            "Epoch 61/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.5218 - accuracy: 0.7897\n",
            "Epoch 62/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.4641 - accuracy: 0.8007\n",
            "Epoch 63/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.5517 - accuracy: 0.7897\n",
            "Epoch 64/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.4700 - accuracy: 0.8118\n",
            "Epoch 65/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.4997 - accuracy: 0.7749\n",
            "Epoch 66/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.5245 - accuracy: 0.7897\n",
            "Epoch 67/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.4319 - accuracy: 0.8118\n",
            "Epoch 68/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.4404 - accuracy: 0.8118\n",
            "Epoch 69/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.4262 - accuracy: 0.7970\n",
            "Epoch 70/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.4020 - accuracy: 0.8266\n",
            "Epoch 71/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.4217 - accuracy: 0.8266\n",
            "Epoch 72/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.4555 - accuracy: 0.7970\n",
            "Epoch 73/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.5312 - accuracy: 0.8007\n",
            "Epoch 74/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.5021 - accuracy: 0.8007\n",
            "Epoch 75/500\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 0.4667 - accuracy: 0.8192\n",
            "Epoch 76/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.4063 - accuracy: 0.8044\n",
            "Epoch 77/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.4001 - accuracy: 0.8192\n",
            "Epoch 78/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.4203 - accuracy: 0.8007\n",
            "Epoch 79/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.4007 - accuracy: 0.8266\n",
            "Epoch 80/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.4058 - accuracy: 0.8376\n",
            "Epoch 81/500\n",
            "14/14 [==============================] - 1s 94ms/step - loss: 0.4031 - accuracy: 0.8303\n",
            "Epoch 82/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.3685 - accuracy: 0.8450\n",
            "Epoch 83/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.3994 - accuracy: 0.8339\n",
            "Epoch 84/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.4265 - accuracy: 0.8450\n",
            "Epoch 85/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.4000 - accuracy: 0.8561\n",
            "Epoch 86/500\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 0.3475 - accuracy: 0.8487\n",
            "Epoch 87/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.3845 - accuracy: 0.8376\n",
            "Epoch 88/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.4054 - accuracy: 0.8524\n",
            "Epoch 89/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.3721 - accuracy: 0.8450\n",
            "Epoch 90/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.3755 - accuracy: 0.8376\n",
            "Epoch 91/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.4133 - accuracy: 0.8450\n",
            "Epoch 92/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.4191 - accuracy: 0.8081\n",
            "Epoch 93/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.3950 - accuracy: 0.8524\n",
            "Epoch 94/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.3925 - accuracy: 0.8339\n",
            "Epoch 95/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.3984 - accuracy: 0.8487\n",
            "Epoch 96/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.3697 - accuracy: 0.8708\n",
            "Epoch 97/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.3621 - accuracy: 0.8487\n",
            "Epoch 98/500\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 0.3715 - accuracy: 0.8450\n",
            "Epoch 99/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.3608 - accuracy: 0.8413\n",
            "Epoch 100/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.3943 - accuracy: 0.8450\n",
            "Epoch 101/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.3933 - accuracy: 0.8303\n",
            "Epoch 102/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.3536 - accuracy: 0.8413\n",
            "Epoch 103/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.3566 - accuracy: 0.8524\n",
            "Epoch 104/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.3596 - accuracy: 0.8487\n",
            "Epoch 105/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.3185 - accuracy: 0.8524\n",
            "Epoch 106/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.3016 - accuracy: 0.8487\n",
            "Epoch 107/500\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 0.3171 - accuracy: 0.8303\n",
            "Epoch 108/500\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 0.3336 - accuracy: 0.8413\n",
            "Epoch 109/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.3304 - accuracy: 0.8561\n",
            "Epoch 110/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.3403 - accuracy: 0.8598\n",
            "Epoch 111/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.3412 - accuracy: 0.8672\n",
            "Epoch 112/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.3700 - accuracy: 0.8745\n",
            "Epoch 113/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.3639 - accuracy: 0.8487\n",
            "Epoch 114/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.3405 - accuracy: 0.8524\n",
            "Epoch 115/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.3085 - accuracy: 0.8672\n",
            "Epoch 116/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.3660 - accuracy: 0.8672\n",
            "Epoch 117/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.4280 - accuracy: 0.8487\n",
            "Epoch 118/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.3735 - accuracy: 0.8487\n",
            "Epoch 119/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.3857 - accuracy: 0.8450\n",
            "Epoch 120/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.3981 - accuracy: 0.8376\n",
            "Epoch 121/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.3289 - accuracy: 0.8598\n",
            "Epoch 122/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.3126 - accuracy: 0.8524\n",
            "Epoch 123/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2955 - accuracy: 0.8782\n",
            "Epoch 124/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2901 - accuracy: 0.8782\n",
            "Epoch 125/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.3154 - accuracy: 0.8745\n",
            "Epoch 126/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.3517 - accuracy: 0.8782\n",
            "Epoch 127/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.3052 - accuracy: 0.8745\n",
            "Epoch 128/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.3356 - accuracy: 0.8450\n",
            "Epoch 129/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2874 - accuracy: 0.8561\n",
            "Epoch 130/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.3158 - accuracy: 0.8635\n",
            "Epoch 131/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.2872 - accuracy: 0.8745\n",
            "Epoch 132/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.2771 - accuracy: 0.9004\n",
            "Epoch 133/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2733 - accuracy: 0.8598\n",
            "Epoch 134/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2585 - accuracy: 0.8856\n",
            "Epoch 135/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.2924 - accuracy: 0.8561\n",
            "Epoch 136/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.2651 - accuracy: 0.8930\n",
            "Epoch 137/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2729 - accuracy: 0.8856\n",
            "Epoch 138/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2981 - accuracy: 0.8782\n",
            "Epoch 139/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.3433 - accuracy: 0.8745\n",
            "Epoch 140/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.3317 - accuracy: 0.8598\n",
            "Epoch 141/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.3082 - accuracy: 0.8782\n",
            "Epoch 142/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2944 - accuracy: 0.8893\n",
            "Epoch 143/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2612 - accuracy: 0.8745\n",
            "Epoch 144/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2893 - accuracy: 0.8487\n",
            "Epoch 145/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2906 - accuracy: 0.8967\n",
            "Epoch 146/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2864 - accuracy: 0.8856\n",
            "Epoch 147/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2785 - accuracy: 0.8893\n",
            "Epoch 148/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2551 - accuracy: 0.8967\n",
            "Epoch 149/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2862 - accuracy: 0.8819\n",
            "Epoch 150/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2515 - accuracy: 0.8819\n",
            "Epoch 151/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2595 - accuracy: 0.8967\n",
            "Epoch 152/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2649 - accuracy: 0.8893\n",
            "Epoch 153/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.3014 - accuracy: 0.8819\n",
            "Epoch 154/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2640 - accuracy: 0.8893\n",
            "Epoch 155/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2723 - accuracy: 0.8893\n",
            "Epoch 156/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2914 - accuracy: 0.8893\n",
            "Epoch 157/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2967 - accuracy: 0.9077\n",
            "Epoch 158/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2725 - accuracy: 0.8967\n",
            "Epoch 159/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2684 - accuracy: 0.8819\n",
            "Epoch 160/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2635 - accuracy: 0.8967\n",
            "Epoch 161/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2624 - accuracy: 0.8967\n",
            "Epoch 162/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2819 - accuracy: 0.9004\n",
            "Epoch 163/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2543 - accuracy: 0.8856\n",
            "Epoch 164/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2283 - accuracy: 0.9004\n",
            "Epoch 165/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2352 - accuracy: 0.8930\n",
            "Epoch 166/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2828 - accuracy: 0.8967\n",
            "Epoch 167/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2540 - accuracy: 0.9004\n",
            "Epoch 168/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2465 - accuracy: 0.8930\n",
            "Epoch 169/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2579 - accuracy: 0.9041\n",
            "Epoch 170/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2431 - accuracy: 0.8930\n",
            "Epoch 171/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2362 - accuracy: 0.8930\n",
            "Epoch 172/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2305 - accuracy: 0.9299\n",
            "Epoch 173/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2332 - accuracy: 0.9299\n",
            "Epoch 174/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2192 - accuracy: 0.9114\n",
            "Epoch 175/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2358 - accuracy: 0.9077\n",
            "Epoch 176/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2200 - accuracy: 0.9041\n",
            "Epoch 177/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2421 - accuracy: 0.9114\n",
            "Epoch 178/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2582 - accuracy: 0.9336\n",
            "Epoch 179/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2401 - accuracy: 0.9004\n",
            "Epoch 180/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2316 - accuracy: 0.9041\n",
            "Epoch 181/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2306 - accuracy: 0.9225\n",
            "Epoch 182/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2360 - accuracy: 0.9041\n",
            "Epoch 183/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2333 - accuracy: 0.9151\n",
            "Epoch 184/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2214 - accuracy: 0.9151\n",
            "Epoch 185/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2309 - accuracy: 0.9114\n",
            "Epoch 186/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2225 - accuracy: 0.9188\n",
            "Epoch 187/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.2054 - accuracy: 0.9225\n",
            "Epoch 188/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2243 - accuracy: 0.9151\n",
            "Epoch 189/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1996 - accuracy: 0.8967\n",
            "Epoch 190/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2364 - accuracy: 0.8930\n",
            "Epoch 191/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1950 - accuracy: 0.9077\n",
            "Epoch 192/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2262 - accuracy: 0.9151\n",
            "Epoch 193/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2251 - accuracy: 0.9151\n",
            "Epoch 194/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2167 - accuracy: 0.9077\n",
            "Epoch 195/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2287 - accuracy: 0.9077\n",
            "Epoch 196/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.2194 - accuracy: 0.9077\n",
            "Epoch 197/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2110 - accuracy: 0.9077\n",
            "Epoch 198/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.2231 - accuracy: 0.9151\n",
            "Epoch 199/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2207 - accuracy: 0.9188\n",
            "Epoch 200/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.2403 - accuracy: 0.9151\n",
            "Epoch 201/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2263 - accuracy: 0.9077\n",
            "Epoch 202/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.2311 - accuracy: 0.9299\n",
            "Epoch 203/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2150 - accuracy: 0.9225\n",
            "Epoch 204/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2093 - accuracy: 0.9151\n",
            "Epoch 205/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2342 - accuracy: 0.9114\n",
            "Epoch 206/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2472 - accuracy: 0.8967\n",
            "Epoch 207/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2276 - accuracy: 0.8930\n",
            "Epoch 208/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2063 - accuracy: 0.9188\n",
            "Epoch 209/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2068 - accuracy: 0.9041\n",
            "Epoch 210/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2515 - accuracy: 0.8893\n",
            "Epoch 211/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.2056 - accuracy: 0.9188\n",
            "Epoch 212/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2030 - accuracy: 0.9004\n",
            "Epoch 213/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2221 - accuracy: 0.9188\n",
            "Epoch 214/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2159 - accuracy: 0.9188\n",
            "Epoch 215/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2037 - accuracy: 0.9188\n",
            "Epoch 216/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2005 - accuracy: 0.9225\n",
            "Epoch 217/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2004 - accuracy: 0.9188\n",
            "Epoch 218/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2476 - accuracy: 0.9114\n",
            "Epoch 219/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.3375 - accuracy: 0.8782\n",
            "Epoch 220/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.3938 - accuracy: 0.8450\n",
            "Epoch 221/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.3515 - accuracy: 0.8303\n",
            "Epoch 222/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.3620 - accuracy: 0.8561\n",
            "Epoch 223/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.3735 - accuracy: 0.8229\n",
            "Epoch 224/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.3437 - accuracy: 0.8339\n",
            "Epoch 225/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.3814 - accuracy: 0.8339\n",
            "Epoch 226/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.3023 - accuracy: 0.8635\n",
            "Epoch 227/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.3152 - accuracy: 0.8708\n",
            "Epoch 228/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2734 - accuracy: 0.9004\n",
            "Epoch 229/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2648 - accuracy: 0.8893\n",
            "Epoch 230/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2501 - accuracy: 0.8967\n",
            "Epoch 231/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.2486 - accuracy: 0.8930\n",
            "Epoch 232/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2282 - accuracy: 0.8930\n",
            "Epoch 233/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2294 - accuracy: 0.8930\n",
            "Epoch 234/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2432 - accuracy: 0.8967\n",
            "Epoch 235/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2106 - accuracy: 0.9077\n",
            "Epoch 236/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2209 - accuracy: 0.9041\n",
            "Epoch 237/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1996 - accuracy: 0.9114\n",
            "Epoch 238/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2080 - accuracy: 0.8967\n",
            "Epoch 239/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2424 - accuracy: 0.8930\n",
            "Epoch 240/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2746 - accuracy: 0.9041\n",
            "Epoch 241/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.3285 - accuracy: 0.9041\n",
            "Epoch 242/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.3076 - accuracy: 0.8561\n",
            "Epoch 243/500\n",
            "14/14 [==============================] - 1s 107ms/step - loss: 0.2254 - accuracy: 0.8819\n",
            "Epoch 244/500\n",
            "14/14 [==============================] - 2s 177ms/step - loss: 0.2480 - accuracy: 0.8893\n",
            "Epoch 245/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2685 - accuracy: 0.9077\n",
            "Epoch 246/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2377 - accuracy: 0.8856\n",
            "Epoch 247/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2145 - accuracy: 0.8930\n",
            "Epoch 248/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2202 - accuracy: 0.9041\n",
            "Epoch 249/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1902 - accuracy: 0.9114\n",
            "Epoch 250/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2192 - accuracy: 0.9004\n",
            "Epoch 251/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.1896 - accuracy: 0.9077\n",
            "Epoch 252/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2155 - accuracy: 0.9188\n",
            "Epoch 253/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1843 - accuracy: 0.9041\n",
            "Epoch 254/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1761 - accuracy: 0.9225\n",
            "Epoch 255/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2051 - accuracy: 0.9188\n",
            "Epoch 256/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1986 - accuracy: 0.9188\n",
            "Epoch 257/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1959 - accuracy: 0.9041\n",
            "Epoch 258/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1852 - accuracy: 0.9077\n",
            "Epoch 259/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1770 - accuracy: 0.9225\n",
            "Epoch 260/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.2555 - accuracy: 0.9041\n",
            "Epoch 261/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2052 - accuracy: 0.9373\n",
            "Epoch 262/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2161 - accuracy: 0.9077\n",
            "Epoch 263/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1982 - accuracy: 0.9114\n",
            "Epoch 264/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2072 - accuracy: 0.9151\n",
            "Epoch 265/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1999 - accuracy: 0.9188\n",
            "Epoch 266/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1883 - accuracy: 0.9262\n",
            "Epoch 267/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2106 - accuracy: 0.9077\n",
            "Epoch 268/500\n",
            "14/14 [==============================] - 1s 92ms/step - loss: 0.1797 - accuracy: 0.9151\n",
            "Epoch 269/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1781 - accuracy: 0.9188\n",
            "Epoch 270/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1778 - accuracy: 0.9151\n",
            "Epoch 271/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.1968 - accuracy: 0.9188\n",
            "Epoch 272/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1772 - accuracy: 0.9262\n",
            "Epoch 273/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2080 - accuracy: 0.9114\n",
            "Epoch 274/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1793 - accuracy: 0.9336\n",
            "Epoch 275/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1875 - accuracy: 0.9151\n",
            "Epoch 276/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1892 - accuracy: 0.9225\n",
            "Epoch 277/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1669 - accuracy: 0.9041\n",
            "Epoch 278/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1787 - accuracy: 0.9077\n",
            "Epoch 279/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1924 - accuracy: 0.9114\n",
            "Epoch 280/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1640 - accuracy: 0.9336\n",
            "Epoch 281/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1808 - accuracy: 0.9188\n",
            "Epoch 282/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2217 - accuracy: 0.9262\n",
            "Epoch 283/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1830 - accuracy: 0.9225\n",
            "Epoch 284/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1780 - accuracy: 0.9262\n",
            "Epoch 285/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1876 - accuracy: 0.9299\n",
            "Epoch 286/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1606 - accuracy: 0.9188\n",
            "Epoch 287/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1956 - accuracy: 0.9188\n",
            "Epoch 288/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1830 - accuracy: 0.9225\n",
            "Epoch 289/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1904 - accuracy: 0.9114\n",
            "Epoch 290/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1748 - accuracy: 0.9373\n",
            "Epoch 291/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1721 - accuracy: 0.9299\n",
            "Epoch 292/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.1842 - accuracy: 0.9336\n",
            "Epoch 293/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1770 - accuracy: 0.9299\n",
            "Epoch 294/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1664 - accuracy: 0.9299\n",
            "Epoch 295/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1596 - accuracy: 0.9225\n",
            "Epoch 296/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1925 - accuracy: 0.9262\n",
            "Epoch 297/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1822 - accuracy: 0.9188\n",
            "Epoch 298/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1704 - accuracy: 0.9262\n",
            "Epoch 299/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.1813 - accuracy: 0.9225\n",
            "Epoch 300/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1998 - accuracy: 0.9225\n",
            "Epoch 301/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2071 - accuracy: 0.9299\n",
            "Epoch 302/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2003 - accuracy: 0.9225\n",
            "Epoch 303/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1745 - accuracy: 0.9299\n",
            "Epoch 304/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1763 - accuracy: 0.9299\n",
            "Epoch 305/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1733 - accuracy: 0.9225\n",
            "Epoch 306/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1706 - accuracy: 0.9262\n",
            "Epoch 307/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1717 - accuracy: 0.9225\n",
            "Epoch 308/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.2051 - accuracy: 0.9188\n",
            "Epoch 309/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.1814 - accuracy: 0.9410\n",
            "Epoch 310/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1927 - accuracy: 0.9188\n",
            "Epoch 311/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1903 - accuracy: 0.9299\n",
            "Epoch 312/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2103 - accuracy: 0.9225\n",
            "Epoch 313/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1888 - accuracy: 0.9299\n",
            "Epoch 314/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1737 - accuracy: 0.9225\n",
            "Epoch 315/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1727 - accuracy: 0.9225\n",
            "Epoch 316/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1971 - accuracy: 0.9114\n",
            "Epoch 317/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2050 - accuracy: 0.9336\n",
            "Epoch 318/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1793 - accuracy: 0.9299\n",
            "Epoch 319/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1951 - accuracy: 0.9262\n",
            "Epoch 320/500\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.1918 - accuracy: 0.9299\n",
            "Epoch 321/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1835 - accuracy: 0.9262\n",
            "Epoch 322/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1759 - accuracy: 0.9299\n",
            "Epoch 323/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1946 - accuracy: 0.9262\n",
            "Epoch 324/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1717 - accuracy: 0.9299\n",
            "Epoch 325/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1772 - accuracy: 0.9373\n",
            "Epoch 326/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1684 - accuracy: 0.9336\n",
            "Epoch 327/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1612 - accuracy: 0.9151\n",
            "Epoch 328/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1775 - accuracy: 0.9188\n",
            "Epoch 329/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1734 - accuracy: 0.9373\n",
            "Epoch 330/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1852 - accuracy: 0.9262\n",
            "Epoch 331/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1821 - accuracy: 0.9373\n",
            "Epoch 332/500\n",
            "14/14 [==============================] - 1s 94ms/step - loss: 0.1713 - accuracy: 0.9410\n",
            "Epoch 333/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2136 - accuracy: 0.9188\n",
            "Epoch 334/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1652 - accuracy: 0.9299\n",
            "Epoch 335/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1761 - accuracy: 0.9225\n",
            "Epoch 336/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1792 - accuracy: 0.9336\n",
            "Epoch 337/500\n",
            "14/14 [==============================] - 1s 93ms/step - loss: 0.1697 - accuracy: 0.9336\n",
            "Epoch 338/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1761 - accuracy: 0.9151\n",
            "Epoch 339/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1557 - accuracy: 0.9373\n",
            "Epoch 340/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1683 - accuracy: 0.9299\n",
            "Epoch 341/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1704 - accuracy: 0.9262\n",
            "Epoch 342/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1828 - accuracy: 0.9262\n",
            "Epoch 343/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1859 - accuracy: 0.9336\n",
            "Epoch 344/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.1688 - accuracy: 0.9262\n",
            "Epoch 345/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1831 - accuracy: 0.9225\n",
            "Epoch 346/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.1784 - accuracy: 0.9225\n",
            "Epoch 347/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1763 - accuracy: 0.9151\n",
            "Epoch 348/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1689 - accuracy: 0.9410\n",
            "Epoch 349/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1574 - accuracy: 0.9262\n",
            "Epoch 350/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1656 - accuracy: 0.9336\n",
            "Epoch 351/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1748 - accuracy: 0.9188\n",
            "Epoch 352/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1660 - accuracy: 0.9225\n",
            "Epoch 353/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1660 - accuracy: 0.9299\n",
            "Epoch 354/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1972 - accuracy: 0.9077\n",
            "Epoch 355/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1753 - accuracy: 0.9262\n",
            "Epoch 356/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1924 - accuracy: 0.9336\n",
            "Epoch 357/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.1713 - accuracy: 0.9262\n",
            "Epoch 358/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1839 - accuracy: 0.9373\n",
            "Epoch 359/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1858 - accuracy: 0.9225\n",
            "Epoch 360/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1821 - accuracy: 0.9225\n",
            "Epoch 361/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1703 - accuracy: 0.9336\n",
            "Epoch 362/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1518 - accuracy: 0.9299\n",
            "Epoch 363/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1833 - accuracy: 0.9188\n",
            "Epoch 364/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1893 - accuracy: 0.9336\n",
            "Epoch 365/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1723 - accuracy: 0.9225\n",
            "Epoch 366/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1701 - accuracy: 0.9410\n",
            "Epoch 367/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1640 - accuracy: 0.9299\n",
            "Epoch 368/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1755 - accuracy: 0.9299\n",
            "Epoch 369/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1611 - accuracy: 0.9373\n",
            "Epoch 370/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1552 - accuracy: 0.9373\n",
            "Epoch 371/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1615 - accuracy: 0.9373\n",
            "Epoch 372/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.1809 - accuracy: 0.9299\n",
            "Epoch 373/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1843 - accuracy: 0.9373\n",
            "Epoch 374/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1477 - accuracy: 0.9410\n",
            "Epoch 375/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1830 - accuracy: 0.9262\n",
            "Epoch 376/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1506 - accuracy: 0.9299\n",
            "Epoch 377/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1551 - accuracy: 0.9225\n",
            "Epoch 378/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1752 - accuracy: 0.9336\n",
            "Epoch 379/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2005 - accuracy: 0.9446\n",
            "Epoch 380/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1768 - accuracy: 0.9299\n",
            "Epoch 381/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1844 - accuracy: 0.9225\n",
            "Epoch 382/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1799 - accuracy: 0.9299\n",
            "Epoch 383/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1679 - accuracy: 0.9188\n",
            "Epoch 384/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1535 - accuracy: 0.9373\n",
            "Epoch 385/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1630 - accuracy: 0.9262\n",
            "Epoch 386/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1822 - accuracy: 0.9225\n",
            "Epoch 387/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1535 - accuracy: 0.9446\n",
            "Epoch 388/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1455 - accuracy: 0.9446\n",
            "Epoch 389/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1524 - accuracy: 0.9373\n",
            "Epoch 390/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1498 - accuracy: 0.9373\n",
            "Epoch 391/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1628 - accuracy: 0.9336\n",
            "Epoch 392/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1592 - accuracy: 0.9373\n",
            "Epoch 393/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1870 - accuracy: 0.9225\n",
            "Epoch 394/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1699 - accuracy: 0.9410\n",
            "Epoch 395/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1603 - accuracy: 0.9373\n",
            "Epoch 396/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1452 - accuracy: 0.9410\n",
            "Epoch 397/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1887 - accuracy: 0.9114\n",
            "Epoch 398/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.1926 - accuracy: 0.9151\n",
            "Epoch 399/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1664 - accuracy: 0.9262\n",
            "Epoch 400/500\n",
            "14/14 [==============================] - 1s 92ms/step - loss: 0.1682 - accuracy: 0.9483\n",
            "Epoch 401/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.1705 - accuracy: 0.9410\n",
            "Epoch 402/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1567 - accuracy: 0.9262\n",
            "Epoch 403/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1759 - accuracy: 0.9299\n",
            "Epoch 404/500\n",
            "14/14 [==============================] - 1s 94ms/step - loss: 0.1719 - accuracy: 0.9299\n",
            "Epoch 405/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1809 - accuracy: 0.9410\n",
            "Epoch 406/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1826 - accuracy: 0.9225\n",
            "Epoch 407/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.1706 - accuracy: 0.9373\n",
            "Epoch 408/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1603 - accuracy: 0.9336\n",
            "Epoch 409/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1456 - accuracy: 0.9336\n",
            "Epoch 410/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1609 - accuracy: 0.9410\n",
            "Epoch 411/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1698 - accuracy: 0.9446\n",
            "Epoch 412/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1708 - accuracy: 0.9410\n",
            "Epoch 413/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1549 - accuracy: 0.9336\n",
            "Epoch 414/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1811 - accuracy: 0.9336\n",
            "Epoch 415/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1482 - accuracy: 0.9373\n",
            "Epoch 416/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.1414 - accuracy: 0.9410\n",
            "Epoch 417/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1927 - accuracy: 0.9373\n",
            "Epoch 418/500\n",
            "14/14 [==============================] - 1s 93ms/step - loss: 0.1521 - accuracy: 0.9336\n",
            "Epoch 419/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1637 - accuracy: 0.9188\n",
            "Epoch 420/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.1806 - accuracy: 0.9262\n",
            "Epoch 421/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1678 - accuracy: 0.9188\n",
            "Epoch 422/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.1733 - accuracy: 0.9410\n",
            "Epoch 423/500\n",
            "14/14 [==============================] - 2s 132ms/step - loss: 0.1610 - accuracy: 0.9299\n",
            "Epoch 424/500\n",
            "14/14 [==============================] - 2s 156ms/step - loss: 0.1604 - accuracy: 0.9336\n",
            "Epoch 425/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.1713 - accuracy: 0.9336\n",
            "Epoch 426/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1728 - accuracy: 0.9225\n",
            "Epoch 427/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.1564 - accuracy: 0.9262\n",
            "Epoch 428/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.1782 - accuracy: 0.9336\n",
            "Epoch 429/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.1765 - accuracy: 0.9225\n",
            "Epoch 430/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1636 - accuracy: 0.9373\n",
            "Epoch 431/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.1601 - accuracy: 0.9373\n",
            "Epoch 432/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.1512 - accuracy: 0.9299\n",
            "Epoch 433/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1556 - accuracy: 0.9410\n",
            "Epoch 434/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1532 - accuracy: 0.9336\n",
            "Epoch 435/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1565 - accuracy: 0.9262\n",
            "Epoch 436/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1920 - accuracy: 0.9336\n",
            "Epoch 437/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.1636 - accuracy: 0.9336\n",
            "Epoch 438/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.1639 - accuracy: 0.9299\n",
            "Epoch 439/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.5854 - accuracy: 0.8192\n",
            "Epoch 440/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.7114 - accuracy: 0.8118\n",
            "Epoch 441/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.7218 - accuracy: 0.8007\n",
            "Epoch 442/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.7328 - accuracy: 0.8155\n",
            "Epoch 443/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.5606 - accuracy: 0.7601\n",
            "Epoch 444/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.5128 - accuracy: 0.8155\n",
            "Epoch 445/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.4468 - accuracy: 0.8339\n",
            "Epoch 446/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.4084 - accuracy: 0.8266\n",
            "Epoch 447/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.4022 - accuracy: 0.8450\n",
            "Epoch 448/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.3801 - accuracy: 0.8708\n",
            "Epoch 449/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.3667 - accuracy: 0.8450\n",
            "Epoch 450/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.3711 - accuracy: 0.8782\n",
            "Epoch 451/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.4007 - accuracy: 0.8745\n",
            "Epoch 452/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.3540 - accuracy: 0.8339\n",
            "Epoch 453/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.3387 - accuracy: 0.9004\n",
            "Epoch 454/500\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.3053 - accuracy: 0.8819\n",
            "Epoch 455/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2869 - accuracy: 0.8745\n",
            "Epoch 456/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.2819 - accuracy: 0.8782\n",
            "Epoch 457/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.2702 - accuracy: 0.8745\n",
            "Epoch 458/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.3090 - accuracy: 0.8745\n",
            "Epoch 459/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2649 - accuracy: 0.9262\n",
            "Epoch 460/500\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.2607 - accuracy: 0.8819\n",
            "Epoch 461/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2578 - accuracy: 0.8819\n",
            "Epoch 462/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2743 - accuracy: 0.8672\n",
            "Epoch 463/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.2586 - accuracy: 0.8819\n",
            "Epoch 464/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.2444 - accuracy: 0.8967\n",
            "Epoch 465/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2458 - accuracy: 0.8893\n",
            "Epoch 466/500\n",
            "14/14 [==============================] - 1s 94ms/step - loss: 0.2324 - accuracy: 0.8635\n",
            "Epoch 467/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.2368 - accuracy: 0.8745\n",
            "Epoch 468/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.2342 - accuracy: 0.8819\n",
            "Epoch 469/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.3199 - accuracy: 0.8524\n",
            "Epoch 470/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.3631 - accuracy: 0.8672\n",
            "Epoch 471/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.3409 - accuracy: 0.8635\n",
            "Epoch 472/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.3539 - accuracy: 0.8450\n",
            "Epoch 473/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.3161 - accuracy: 0.8672\n",
            "Epoch 474/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.3737 - accuracy: 0.8450\n",
            "Epoch 475/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.3112 - accuracy: 0.8745\n",
            "Epoch 476/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.3270 - accuracy: 0.8635\n",
            "Epoch 477/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2910 - accuracy: 0.8782\n",
            "Epoch 478/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2628 - accuracy: 0.8782\n",
            "Epoch 479/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2356 - accuracy: 0.9004\n",
            "Epoch 480/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2291 - accuracy: 0.8967\n",
            "Epoch 481/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2404 - accuracy: 0.8930\n",
            "Epoch 482/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2176 - accuracy: 0.9041\n",
            "Epoch 483/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2217 - accuracy: 0.8856\n",
            "Epoch 484/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2221 - accuracy: 0.8782\n",
            "Epoch 485/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2403 - accuracy: 0.8635\n",
            "Epoch 486/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2260 - accuracy: 0.9114\n",
            "Epoch 487/500\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.2132 - accuracy: 0.8930\n",
            "Epoch 488/500\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.2310 - accuracy: 0.9188\n",
            "Epoch 489/500\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.2190 - accuracy: 0.9041\n",
            "Epoch 490/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.2053 - accuracy: 0.8967\n",
            "Epoch 491/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2505 - accuracy: 0.8967\n",
            "Epoch 492/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2339 - accuracy: 0.9004\n",
            "Epoch 493/500\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.2013 - accuracy: 0.9004\n",
            "Epoch 494/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2299 - accuracy: 0.8856\n",
            "Epoch 495/500\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.1931 - accuracy: 0.8967\n",
            "Epoch 496/500\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1912 - accuracy: 0.8967\n",
            "Epoch 497/500\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.2421 - accuracy: 0.9041\n",
            "Epoch 498/500\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.1946 - accuracy: 0.8856\n",
            "Epoch 499/500\n",
            "14/14 [==============================] - 1s 93ms/step - loss: 0.2223 - accuracy: 0.8893\n",
            "Epoch 500/500\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2677 - accuracy: 0.8930\n",
            "(181, 13)\n",
            "[ 0  0  9  0  0  0  9  8  0  7  0  0  0  0  0  0  0  0  0  2  9  0  0  9\n",
            "  0  0  0  0  0  2  0  0  0  0  0  0  0  9  9  2  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  9  0  0  2  0  0  1  0  0  1  0  9  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0 12  0  9  0  0  9  0  0\n",
            "  0  0  0  0  0  0  0  2  9  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  9  1  0  0  0  0  0  0  0  0  0  0  1  0  5  0  0  0  0  0  0  3  0  0\n",
            "  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  9  0  0  0  0  0  0  0  0  3 12  0  0]\n",
            "[ 0 12  9  0  0  9  9  8  0  2  2  1  0  0  1  0  0  5  2  2  1  1  0  0\n",
            "  9  0  0  0  9  1  0  0  1  9  3  0  5  9  6 12  0 12  0  0  0  9  3  0\n",
            "  0 12  0 12  0  0  0  0  1  0  4  4  9  2  1  0 10  0  9  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  4  5  0 12  9  0  5  0  0  0  0  0  9  0 10  3  0\n",
            "  0  6  0  0  0  0  0  2 10  9  0  0  0  5  4  0  5  0  0  1 12  0  1  9\n",
            "  9  1  0  9  0  5  0  1  0  0  0  0  8  5 12  0  9  0  0  3 12 11  5  0\n",
            "  0  9  4  9  0  8  5  4  0  9  0  0  0  9  0  2  0  0  0  1  9  0  0  0\n",
            "  9  0  0  0  9  1  0  5  5  0  0  0  0]\n",
            "Merged Model Accuracy: 53.591160220994475 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #####   Generating confusion matrix of HEARTBEATS\n",
        "\n",
        "# import sklearn.metrics\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# class_labels = ['0','1', '2', '3', '4', '5','6', '7', '8', '9', '10','11', '12']\n",
        "# confusion_matrix = confusion_matrix(max_testNM, preddd)\n",
        "# sns.heatmap(confusion_matrix, xticklabels = class_labels, yticklabels = class_labels, annot = True, linewidths = 0.1, fmt='d', cmap = 'YlGnBu')\n",
        "# plt.title(\"Confusion matrix\", fontsize = 15)\n",
        "# plt.ylabel('True label')\n",
        "# plt.xlabel('Predicted label')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "IJjBQjVdHVyk"
      },
      "execution_count": 62,
      "outputs": []
    }
  ]
}